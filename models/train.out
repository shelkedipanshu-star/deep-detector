Epoch 1: train_loss=0.5705 val_acc=1.0000 val_prec=1.0000 val_rec=1.0000 val_f1=1.0000
Saved best checkpoint to C:\meet\deep\models\best.pt
Epoch 2: train_loss=0.4220 val_acc=1.0000 val_prec=1.0000 val_rec=1.0000 val_f1=1.0000
Epoch 3: train_loss=0.3615 val_acc=1.0000 val_prec=1.0000 val_rec=1.0000 val_f1=1.0000
Epoch 4: train_loss=0.3292 val_acc=1.0000 val_prec=1.0000 val_rec=1.0000 val_f1=1.0000
Epoch 5: train_loss=0.3308 val_acc=1.0000 val_prec=1.0000 val_rec=1.0000 val_f1=1.0000
Epoch 6: train_loss=0.3447 val_acc=1.0000 val_prec=1.0000 val_rec=1.0000 val_f1=1.0000
Epoch 7: train_loss=0.2969 val_acc=1.0000 val_prec=1.0000 val_rec=1.0000 val_f1=1.0000
Epoch 8: train_loss=0.3045 val_acc=1.0000 val_prec=1.0000 val_rec=1.0000 val_f1=1.0000
Early stopping triggered.
Threshold calibration skipped due to error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Training complete. Best F1: 1.0
